{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QerpgDHOan2w"
      },
      "outputs": [],
      "source": [
        "#21. Write a Python program to train an SVM Classifier on the Iris dataset and evaluate accuracy:\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the SVM classifier\n",
        "svm_classifier = svm.SVC()\n",
        "\n",
        "# Define hyperparameters for tuning\n",
        "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly']}\n",
        "\n",
        "# Perform grid search for hyperparameter tuning\n",
        "grid_search = GridSearchCV(svm_classifier, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score:\", best_score)\n",
        "\n",
        "# Train the SVM classifier with the best parameters\n",
        "best_svm_classifier = grid_search.best_estimator_\n",
        "best_svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "#22 Write a Python program to train two SVM classifiers with Linear and RBF kernels on the Wine dataset, then compare their accuracies:\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Wine dataset\n",
        "wine = datasets.load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features by removing the mean and scaling to unit variance\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define the SVM classifiers\n",
        "svm_linear = svm.SVC(kernel='linear', C=1)\n",
        "svm_rbf = svm.SVC(kernel='rbf', C=1)\n",
        "\n",
        "# Train the SVM classifiers\n",
        "svm_linear.fit(X_train, y_train)\n",
        "svm_rbf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_linear = svm_linear.predict(X_test)\n",
        "y_pred_rbf = svm_rbf.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the classifiers\n",
        "accuracy_linear = metrics.accuracy_score(y_test, y_pred_linear)\n",
        "accuracy_rbf = metrics.accuracy_score(y_test, y_pred_rbf)\n",
        "\n",
        "print(\"Accuracy (Linear Kernel):\", accuracy_linear)\n",
        "print(\"Accuracy (RBF Kernel):\", accuracy_rbf)\n",
        "\n",
        "# Print the classification reports\n",
        "print(\"Classification Report (Linear Kernel):\")\n",
        "print(metrics.classification_report(y_test, y_pred_linear))\n",
        "print(\"Classification Report (RBF Kernel):\")\n",
        "print(metrics.classification_report(y_test, y_pred_rbf))\n",
        "\n",
        "# Print the confusion matrices\n",
        "print(\"Confusion Matrix (Linear Kernel):\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred_linear))\n",
        "print(\"Confusion Matrix (RBF Kernel):\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred_rbf))\n",
        "\n",
        "# Compare the accuracies\n",
        "if accuracy_linear > accuracy_rbf:\n",
        "    print(\"Linear kernel performs better with an accuracy of\", accuracy_linear)\n",
        "elif accuracy_rbf > accuracy_linear:\n",
        "    print(\"RBF kernel performs better with an accuracy of\", accuracy_rbf)\n",
        "else:\n",
        "    print(\"Both kernels perform equally well with an accuracy of\", accuracy_linear)\n",
        "\n",
        "#23 Write a Python program to train an SVM Regressor (SVR) on a housing dataset and evaluate it using Mean Squared Error (MSE):\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Boston Housing dataset\n",
        "from sklearn.datasets import load_boston\n",
        "boston = load_boston()\n",
        "X = boston.data\n",
        "y = boston.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features by removing the mean and scaling to unit variance\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define the SVM Regressor\n",
        "svr = svm.SVR(kernel='rbf', C=100, epsilon=0.1)\n",
        "\n",
        "# Train the SVM Regressor\n",
        "svr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svr.predict(X_test)\n",
        "\n",
        "# Evaluate the Mean Squared Error (MSE)\n",
        "mse = metrics.mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "# Evaluate the Root Mean Squared Error (RMSE)\n",
        "rmse = mse ** 0.5\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "\n",
        "# Evaluate the Mean Absolute Error (MAE)\n",
        "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "\n",
        "# Evaluate the R-Squared value\n",
        "r2 = metrics.r2_score(y_test, y_pred)\n",
        "print(\"R-Squared value:\", r2)\n",
        "\n",
        "\n",
        "#24 Write a Python program to train an SVM Classifier with a Polynomial Kernel and visualize the decision boundary:\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "\n",
        "# Generate a sample dataset\n",
        "np.random.seed(0)\n",
        "mean1 = [0, 0]\n",
        "cov1 = [[1, 0.5], [0.5, 1]]\n",
        "data1 = np.random.multivariate_normal(mean1, cov1, 50)\n",
        "\n",
        "mean2 = [5, 5]\n",
        "cov2 = [[1, 0.5], [0.5, 1]]\n",
        "data2 = np.random.multivariate_normal(mean2, cov2, 50)\n",
        "\n",
        "X = np.vstack((data1, data2))\n",
        "y = np.hstack((np.zeros(50), np.ones(50)))\n",
        "\n",
        "# Train the SVM Classifier with Polynomial Kernel\n",
        "svm_classifier = svm.SVC(kernel='poly', degree=3, C=1)\n",
        "svm_classifier.fit(X, y)\n",
        "\n",
        "# Plot the decision boundary\n",
        "plt.figure(figsize=(8, 6))\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
        "Z = svm_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "plt.contourf(xx, yy, Z, alpha=0.8)\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('SVM Classifier with Polynomial Kernel')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#25 Write a Python program to train a Gaussian Na√Øve Bayes classifier on the Breast Cancer dataset and evaluate accuracy:\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "breast_cancer = datasets.load_breast_cancer()\n",
        "X = breast_cancer.data\n",
        "y = breast_cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features by removing the mean and scaling to unit variance\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define the Gaussian Na√Øve Bayes classifier\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# Train the Gaussian Na√Øve Bayes classifier\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "#26  Write a Python program to train a Multinomial Na√Øve Bayes classifier for text classification using the 20 Newsgroups dataset.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "\n",
        "# Load the 20 Newsgroups dataset\n",
        "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(newsgroups.data, newsgroups.target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a CountVectorizer object\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "\n",
        "# Fit the vectorizer to the training data and transform both the training and testing data\n",
        "X_train_count = vectorizer.fit_transform(X_train)\n",
        "X_test_count = vectorizer.transform(X_test)\n",
        "\n",
        "# Define the Multinomial Na√Øve Bayes classifier\n",
        "mnb = MultinomialNB()\n",
        "\n",
        "# Train the Multinomial Na√Øve Bayes classifier\n",
        "mnb.fit(X_train_count, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = mnb.predict(X_test_count)\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "#27 Write a Python program to train an SVM Classifier with different C values and compare the decision boundaries visually\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "\n",
        "# Generate a sample dataset\n",
        "np.random.seed(0)\n",
        "mean1 = [0, 0]\n",
        "cov1 = [[1, 0.5], [0.5, 1]]\n",
        "data1 = np.random.multivariate_normal(mean1, cov1, 50)\n",
        "\n",
        "mean2 = [5, 5]\n",
        "cov2 = [[1, 0.5], [0.5, 1]]\n",
        "data2 = np.random.multivariate_normal(mean2, cov2, 50)\n",
        "\n",
        "X = np.vstack((data1, data2))\n",
        "y = np.hstack((np.zeros(50), np.ones(50)))\n",
        "\n",
        "# Train SVM Classifiers with different C values\n",
        "C_values = [0.1, 1, 10]\n",
        "fig, axs = plt.subplots(1, len(C_values), figsize=(15, 5))\n",
        "\n",
        "for i, C in enumerate(C_values):\n",
        "    svm_classifier = svm.SVC(kernel='rbf', C=C)\n",
        "    svm_classifier.fit(X, y)\n",
        "\n",
        "    # Plot the decision boundary\n",
        "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
        "    Z = svm_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    axs[i].contourf(xx, yy, Z, alpha=0.8)\n",
        "    axs[i].scatter(X[:, 0], X[:, 1], c=y)\n",
        "    axs[i].set_title(f\"C = {C}\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#28 Write a Python program to train a Bernoulli Na√Øve Bayes classifier for binary classification on a dataset with binary features\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "# Generate a sample dataset with binary features\n",
        "np.random.seed(0)\n",
        "X = np.random.randint(2, size=(100, 10))\n",
        "y = np.random.randint(2, size=(100))\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Bernoulli Na√Øve Bayes classifier\n",
        "bnb = BernoulliNB()\n",
        "\n",
        "# Train the Bernoulli Na√Øve Bayes classifier\n",
        "bnb.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = bnb.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "#29 Write a Python program to apply feature scaling before training an SVM model and compare results with unscaled data\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an SVM model without feature scaling\n",
        "svm_unscaled = svm.SVC(kernel='rbf', C=1)\n",
        "svm_unscaled.fit(X_train, y_train)\n",
        "y_pred_unscaled = svm_unscaled.predict(X_test)\n",
        "accuracy_unscaled = metrics.accuracy_score(y_test, y_pred_unscaled)\n",
        "print(\"Accuracy without feature scaling:\", accuracy_unscaled)\n",
        "\n",
        "# Apply feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train an SVM model with feature scaling\n",
        "svm_scaled = svm.SVC(kernel='rbf', C=1)\n",
        "svm_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = svm_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = metrics.accuracy_score(y_test, y_pred_scaled)\n",
        "print(\"Accuracy with feature scaling:\", accuracy_scaled)\n",
        "\n",
        "# Compare the results\n",
        "print(\"Difference in accuracy:\", accuracy_scaled - accuracy_unscaled)\n",
        "\n",
        "# Print the classification reports\n",
        "print(\"Classification Report without feature scaling:\")\n",
        "print(metrics.classification_report(y_test, y_pred_unscaled))\n",
        "print(\"Classification Report with feature scaling:\")\n",
        "print(metrics.classification_report(y_test, y_pred_scaled))\n",
        "\n",
        "\n",
        "#30 Write a Python program to train a Gaussian Na√Øve Bayes model and compare the predictions before and after Laplace Smoothing\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a custom Gaussian Na√Øve Bayes class with Laplace Smoothing\n",
        "class GaussianNBWithLaplace(GaussianNB):\n",
        "    def __init__(self, var_smoothing=1e-9):\n",
        "        super().__init__(var_smoothing=var_smoothing)\n",
        "\n",
        "# Train a Gaussian Na√Øve Bayes model without Laplace Smoothing\n",
        "gnb_without_laplace = GaussianNB(var_smoothing=0)\n",
        "gnb_without_laplace.fit(X_train, y_train)\n",
        "y_pred_without_laplace = gnb_without_laplace.predict(X_test)\n",
        "\n",
        "# Train a Gaussian Na√Øve Bayes model with Laplace Smoothing\n",
        "gnb_with_laplace = GaussianNBWithLaplace(var_smoothing=1e-9)\n",
        "gnb_with_laplace.fit(X_train, y_train)\n",
        "y_pred_with_laplace = gnb_with_laplace.predict(X_test)\n",
        "\n",
        "# Compare the predictions\n",
        "accuracy_without_laplace = metrics.accuracy_score(y_test, y_pred_without_laplace)\n",
        "accuracy_with_laplace = metrics.accuracy_score(y_test, y_pred_with_laplace)\n",
        "print(\"Accuracy without Laplace Smoothing:\", accuracy_without_laplace)\n",
        "print(\"Accuracy with Laplace Smoothing:\", accuracy_with_laplace)\n",
        "\n",
        "# Print the classification reports\n",
        "print(\"Classification Report without Laplace Smoothing:\")\n",
        "print(metrics.classification_report(y_test, y_pred_without_laplace))\n",
        "print(\"Classification Report with Laplace Smoothing:\")\n",
        "print(metrics.classification_report(y_test, y_pred_with_laplace))\n",
        "\n",
        "\n",
        "#31 Write a Python program to train an SVM Classifier and use GridSearchCV to tune the hyperparameters (C,gamma, kernel)\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "\n",
        "# Load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the SVM Classifier\n",
        "svm_classifier = svm.SVC()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': ['scale', 'auto', 0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf', 'poly']\n",
        "}\n",
        "\n",
        "# Perform grid search\n",
        "grid_search = GridSearchCV(svm_classifier, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters and the best score\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Score:\", best_score)\n",
        "\n",
        "# Train an SVM Classifier with the best parameters\n",
        "best_svm_classifier = grid_search.best_estimator_\n",
        "best_svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(metrics.confusion_matrix(y_test, y_pred))\n",
        "\n",
        "\n",
        "#32 Write a Python program to train an SVM Classifier on an imbalanced dataset and apply class weighting and check it improve accuracy\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.datasets import make_classification\n",
        "import numpy as np\n",
        "\n",
        "# Generate an imbalanced dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=0, n_repeated=0, n_classes=2, weights=[0.9, 0.1], random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an SVM Classifier without class weighting\n",
        "svm_unweighted = svm.SVC(kernel='rbf', C=1)\n",
        "svm_unweighted.fit(X_train, y_train)\n",
        "y_pred_unweighted = svm_unweighted.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the unweighted classifier\n",
        "accuracy_unweighted = metrics.accuracy_score(y_test, y_pred_unweighted)\n",
        "print(\"Accuracy without class weighting:\", accuracy_unweighted)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report without class weighting:\")\n",
        "print(metrics.classification_report(y_test, y_pred_unweighted))\n",
        "\n",
        "# Train an SVM Classifier with class weighting\n",
        "svm_weighted = svm.SVC(kernel='rbf', C=1, class_weight='balanced')\n",
        "svm_weighted.fit(X_train, y_train)\n",
        "y_pred_weighted = svm_weighted.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the weighted classifier\n",
        "accuracy_weighted = metrics.accuracy_score(y_test, y_pred_weighted)\n",
        "print(\"Accuracy with class weighting:\", accuracy_weighted)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report with class weighting:\")\n",
        "print(metrics.classification_report(y_test, y_pred_weighted))\n",
        "\n",
        "# Compare the F1 scores\n",
        "f1_unweighted = metrics.f1_score(y_test, y_pred_unweighted, average='macro')\n",
        "f1_weighted = metrics.f1_score(y_test, y_pred_weighted, average='macro')\n",
        "print(\"F1 score without class weighting:\", f1_unweighted)\n",
        "print(\"F1 score with class weighting:\", f1_weighted)\n",
        "\n",
        "\n",
        "#33 Write a Python program to implement a Na√Øve Bayes classifier for spam detection using email data\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "\n",
        "# Load the email dataset\n",
        "# For demonstration purposes, we'll use a sample dataset\n",
        "data = {\n",
        "    'email': [\n",
        "        'You won a prize, claim now!',\n",
        "        'Meeting at 2 PM today',\n",
        "        'Get free cash now!',\n",
        "        'Project update: everything is fine',\n",
        "        'Win a free trip to Hawaii!',\n",
        "        'New policy announcement',\n",
        "        'You are a winner!',\n",
        "        'Client feedback meeting',\n",
        "        'Make money fast!',\n",
        "        'Team lunch at 12 PM'\n",
        "    ],\n",
        "    'label': ['spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['email'], df['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a CountVectorizer object\n",
        "vectorizer = CountVectorizer(stop_words='english')\n",
        "\n",
        "# Fit the vectorizer to the training data and transform both the training and testing data\n",
        "X_train_count = vectorizer.fit_transform(X_train)\n",
        "X_test_count = vectorizer.transform(X_test)\n",
        "\n",
        "# Define the Na√Øve Bayes classifier\n",
        "nb = MultinomialNB()\n",
        "\n",
        "# Train the Na√Øve Bayes classifier\n",
        "nb.fit(X_train_count, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = nb.predict(X_test_count)\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "# Test the classifier with a new email\n",
        "new_email = ['You won a prize!']\n",
        "new_email_count = vectorizer.transform(new_email)\n",
        "prediction = nb.predict(new_email_count)\n",
        "print(\"Prediction:\", prediction)\n",
        "\n",
        "\n",
        "#34 Write a Python program to train an SVM Classifier and a Na√Øve Bayes Classifier on the same dataset and compare their accuracy\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "\n",
        "# Load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an SVM Classifier\n",
        "svm_classifier = svm.SVC(kernel='rbf', C=1)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "y_pred_svm = svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the SVM Classifier\n",
        "accuracy_svm = metrics.accuracy_score(y_test, y_pred_svm)\n",
        "print(\"Accuracy of SVM Classifier:\", accuracy_svm)\n",
        "\n",
        "# Print the classification report for SVM Classifier\n",
        "print(\"Classification Report for SVM Classifier:\")\n",
        "print(metrics.classification_report(y_test, y_pred_svm))\n",
        "\n",
        "# Train a Na√Øve Bayes Classifier\n",
        "nb_classifier = GaussianNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "y_pred_nb = nb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the Na√Øve Bayes Classifier\n",
        "accuracy_nb = metrics.accuracy_score(y_test, y_pred_nb)\n",
        "print(\"Accuracy of Na√Øve Bayes Classifier:\", accuracy_nb)\n",
        "\n",
        "# Print the classification report for Na√Øve Bayes Classifier\n",
        "print(\"Classification Report for Na√Øve Bayes Classifier:\")\n",
        "print(metrics.classification_report(y_test, y_pred_nb))\n",
        "\n",
        "# Compare the accuracy of both classifiers\n",
        "print(\"Difference in accuracy:\", accuracy_svm - accuracy_nb)\n",
        "\n",
        "# Determine which classifier is better\n",
        "if accuracy_svm > accuracy_nb:\n",
        "    print(\"SVM Classifier is better\")\n",
        "elif accuracy_nb > accuracy_svm:\n",
        "    print(\"Na√Øve Bayes Classifier is better\")\n",
        "else:\n",
        "    print(\"Both classifiers have the same accuracy\")\n",
        "\n",
        "\n",
        "#35 Write a Python program to perform feature selection before training a Na√Øve Bayes classifier and compare results\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "\n",
        "# Load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Na√Øve Bayes classifier without feature selection\n",
        "nb_without_fs = GaussianNB()\n",
        "nb_without_fs.fit(X_train, y_train)\n",
        "y_pred_without_fs = nb_without_fs.predict(X_test)\n",
        "accuracy_without_fs = metrics.accuracy_score(y_test, y_pred_without_fs)\n",
        "print(\"Accuracy without feature selection:\", accuracy_without_fs)\n",
        "\n",
        "# Perform feature selection using SelectKBest\n",
        "selector = SelectKBest(score_func=chi2, k=2)\n",
        "X_train_selected = selector.fit_transform(X_train, y_train)\n",
        "X_test_selected = selector.transform(X_test)\n",
        "\n",
        "# Train a Na√Øve Bayes classifier with feature selection\n",
        "nb_with_fs = GaussianNB()\n",
        "nb_with_fs.fit(X_train_selected, y_train)\n",
        "y_pred_with_fs = nb_with_fs.predict(X_test_selected)\n",
        "accuracy_with_fs = metrics.accuracy_score(y_test, y_pred_with_fs)\n",
        "print(\"Accuracy with feature selection:\", accuracy_with_fs)\n",
        "\n",
        "# Compare the results\n",
        "print(\"Difference in accuracy:\", accuracy_with_fs - accuracy_without_fs)\n",
        "\n",
        "# Print the classification reports\n",
        "print(\"Classification Report without feature selection:\")\n",
        "print(metrics.classification_report(y_test, y_pred_without_fs))\n",
        "print(\"Classification Report with feature selection:\")\n",
        "print(metrics.classification_report(y_test, y_pred_with_fs))\n",
        "\n",
        "\n",
        "#36 Write a Python program to train an SVM Classifier using One-vs-Rest (OvR) and One-vs-One (OvO) strategies on the Wine dataset and compare their accuracy=\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "# Load the Wine dataset\n",
        "wine = datasets.load_wine()\n",
        "X = wine.data\n",
        "y = wine.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an SVM Classifier using One-vs-Rest (OvR) strategy\n",
        "ovr_svm = OneVsRestClassifier(svm.SVC(kernel='rbf', C=1))\n",
        "ovr_svm.fit(X_train, y_train)\n",
        "y_pred_ovr = ovr_svm.predict(X_test)\n",
        "accuracy_ovr = metrics.accuracy_score(y_test, y_pred_ovr)\n",
        "print(\"Accuracy of OvR SVM Classifier:\", accuracy_ovr)\n",
        "\n",
        "# Train an SVM Classifier using One-vs-One (OvO) strategy\n",
        "ovo_svm = OneVsOneClassifier(svm.SVC(kernel='rbf', C=1))\n",
        "ovo_svm.fit(X_train, y_train)\n",
        "y_pred_ovo = ovo_svm.predict(X_test)\n",
        "accuracy_ovo = metrics.accuracy_score(y_test, y_pred_ovo)\n",
        "print(\"Accuracy of OvO SVM Classifier:\", accuracy_ovo)\n",
        "\n",
        "# Compare the accuracy of both classifiers\n",
        "print(\"Difference in accuracy:\", accuracy_ovr - accuracy_ovo)\n",
        "\n",
        "# Determine which classifier is better\n",
        "if accuracy_ovr > accuracy_ovo:\n",
        "    print(\"OvR SVM Classifier is better\")\n",
        "elif accuracy_ovo > accuracy_ovr:\n",
        "    print(\"OvO SVM Classifier is better\")\n",
        "else:\n",
        "    print(\"Both classifiers have the same accuracy\")\n",
        "\n",
        "# Print the classification reports\n",
        "print(\"Classification Report for OvR SVM Classifier:\")\n",
        "print(metrics.classification_report(y_test, y_pred_ovr))\n",
        "print(\"Classification Report for OvO SVM Classifier:\")\n",
        "print(metrics.classification_report(y_test, y_pred_ovo))\n",
        "\n",
        "\n",
        "#37 Write a Python program to train an SVM Classifier using Linear, Polynomial, and RBF kernels on the Breast Cancer dataset and compare their accuracy\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "\n",
        "# Load the Breast Cancer dataset\n",
        "breast_cancer = datasets.load_breast_cancer()\n",
        "X = breast_cancer.data\n",
        "y = breast_cancer.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an SVM Classifier with Linear kernel\n",
        "linear_svm = svm.SVC(kernel='linear', C=1)\n",
        "linear_svm.fit(X_train, y_train)\n",
        "y_pred_linear = linear_svm.predict(X_test)\n",
        "accuracy_linear = metrics.accuracy_score(y_test, y_pred_linear)\n",
        "print(\"Accuracy of Linear SVM Classifier:\", accuracy_linear)\n",
        "\n",
        "# Train an SVM Classifier with Polynomial kernel\n",
        "poly_svm = svm.SVC(kernel='poly', degree=3, C=1)\n",
        "poly_svm.fit(X_train, y_train)\n",
        "y_pred_poly = poly_svm.predict(X_test)\n",
        "accuracy_poly = metrics.accuracy_score(y_test, y_pred_poly)\n",
        "print(\"Accuracy of Polynomial SVM Classifier:\", accuracy_poly)\n",
        "\n",
        "# Train an SVM Classifier with RBF kernel\n",
        "rbf_svm = svm.SVC(kernel='rbf', C=1)\n",
        "rbf_svm.fit(X_train, y_train)\n",
        "y_pred_rbf = rbf_svm.predict(X_test)\n",
        "accuracy_rbf = metrics.accuracy_score(y_test, y_pred_rbf)\n",
        "print(\"Accuracy of RBF SVM Classifier:\", accuracy_rbf)\n",
        "\n",
        "# Compare the accuracy of different kernels\n",
        "print(\"Accuracy Comparison:\")\n",
        "print(\"Linear:\", accuracy_linear)\n",
        "print(\"Polynomial:\", accuracy_poly)\n",
        "print(\"RBF:\", accuracy_rbf)\n",
        "\n",
        "# Determine which kernel is better\n",
        "max_accuracy = max(accuracy_linear, accuracy_poly, accuracy_rbf)\n",
        "if max_accuracy == accuracy_linear:\n",
        "    print(\"Linear kernel is better\")\n",
        "elif max_accuracy == accuracy_poly:\n",
        "    print(\"Polynomial kernel is better\")\n",
        "else:\n",
        "    print(\"RBF kernel is better\")\n",
        "\n",
        "# Print the classification reports\n",
        "print(\"Classification Report for Linear SVM Classifier:\")\n",
        "print(metrics.classification_report(y_test, y_pred_linear))\n",
        "print(\"Classification Report for Polynomial SVM Classifier:\")\n",
        "print(metrics.classification_report(y_test, y_pred_poly))\n",
        "print(\"Classification Report for RBF SVM Classifier:\")\n",
        "print(metrics.classification_report(y_test, y_pred_rbf))\n",
        "\n",
        "\n",
        "#38 Write a Python program to train an SVM Classifier using Stratified K-Fold Cross-Validation and compute the average accuracy\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Define the number of folds\n",
        "n_folds = 5\n",
        "\n",
        "# Define the SVM Classifier\n",
        "svm_classifier = svm.SVC(kernel='rbf', C=1)\n",
        "\n",
        "# Define the Stratified K-Fold Cross-Validation object\n",
        "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize a list to store the accuracy scores\n",
        "accuracy_scores = []\n",
        "\n",
        "# Perform Stratified K-Fold Cross-Validation\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Train the SVM Classifier\n",
        "    svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "    # Compute the accuracy score\n",
        "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "    accuracy_scores.append(accuracy)\n",
        "\n",
        "# Compute the average accuracy\n",
        "average_accuracy = np.mean(accuracy_scores)\n",
        "print(\"Average Accuracy:\", average_accuracy)\n",
        "\n",
        "# Print the accuracy scores for each fold\n",
        "print(\"Accuracy Scores for each fold:\")\n",
        "for i, accuracy in enumerate(accuracy_scores):\n",
        "    print(f\"Fold {i+1}: {accuracy}\")\n",
        "\n",
        "# Print the standard deviation of the accuracy scores\n",
        "std_dev = np.std(accuracy_scores)\n",
        "print(\"Standard Deviation of Accuracy Scores:\", std_dev)\n",
        "\n",
        "\n",
        "#39 Write a Python program to train a Na√Øve Bayes classifier using different prior probabilities and compare performance\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=0, n_repeated=0, n_classes=2, weights=[0.7, 0.3], random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Na√Øve Bayes classifier with different prior probabilities\n",
        "prior_probabilities = [[0.5, 0.5], [0.7, 0.3], [0.3, 0.7]]\n",
        "\n",
        "for prior in prior_probabilities:\n",
        "    nb = MultinomialNB(class_prior=prior)\n",
        "    nb.fit(np.abs(X_train), y_train)\n",
        "    y_pred = nb.predict(np.abs(X_test))\n",
        "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "    print(f\"Prior Probabilities: {prior}, Accuracy: {accuracy}\")\n",
        "\n",
        "    # Print the classification report\n",
        "    print(f\"Classification Report for Prior Probabilities {prior}:\")\n",
        "    print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "# Compare the performance\n",
        "# We will compare the accuracy of the models\n",
        "accuracies = []\n",
        "for prior in prior_probabilities:\n",
        "    nb = MultinomialNB(class_prior=prior)\n",
        "    nb.fit(np.abs(X_train), y_train)\n",
        "    y_pred = nb.predict(np.abs(X_test))\n",
        "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "best_prior_index = np.argmax(accuracies)\n",
        "best_prior = prior_probabilities[best_prior_index]\n",
        "print(f\"Best Prior Probabilities: {best_prior}\")\n",
        "\n",
        "#40 Write a Python program to perform Recursive Feature Elimination (RFE) before training an SVM Classifier and compare accuracy\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "\n",
        "# Load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the SVM Classifier\n",
        "svm_classifier = svm.SVC(kernel='rbf', C=1)\n",
        "\n",
        "# Perform Recursive Feature Elimination (RFE)\n",
        "rfe = RFE(estimator=svm_classifier, n_features_to_select=2)\n",
        "rfe.fit(X_train, y_train)\n",
        "\n",
        "# Get the selected features\n",
        "X_train_selected = rfe.transform(X_train)\n",
        "X_test_selected = rfe.transform(X_test)\n",
        "\n",
        "# Train an SVM Classifier with selected features\n",
        "svm_selected = svm.SVC(kernel='rbf', C=1)\n",
        "svm_selected.fit(X_train_selected, y_train)\n",
        "y_pred_selected = svm_selected.predict(X_test_selected)\n",
        "accuracy_selected = metrics.accuracy_score(y_test, y_pred_selected)\n",
        "print(\"Accuracy with selected features:\", accuracy_selected)\n",
        "\n",
        "# Train an SVM Classifier without feature selection\n",
        "svm_without_selection = svm.SVC(kernel='rbf', C=1)\n",
        "svm_without_selection.fit(X_train, y_train)\n",
        "y_pred_without_selection = svm_without_selection.predict(X_test)\n",
        "accuracy_without_selection = metrics.accuracy_score(y_test, y_pred_without_selection)\n",
        "print(\"Accuracy without feature selection:\", accuracy_without_selection)\n",
        "\n",
        "# Compare the accuracy\n",
        "print(\"Difference in accuracy:\", accuracy_selected - accuracy_without_selection)\n",
        "\n",
        "# Print the classification reports\n",
        "print(\"Classification Report with selected features:\")\n",
        "print(metrics.classification_report(y_test, y_pred_selected))\n",
        "print(\"Classification Report without feature selection:\")\n",
        "print(metrics.classification_report(y_test, y_pred_without_selection))\n",
        "\n",
        "\n",
        "#41 Write a Python program to train an SVM Classifier and evaluate its performance using Precision, Recall, and F1-Score instead of accuracy\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "\n",
        "# Load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an SVM Classifier\n",
        "svm_classifier = svm.SVC(kernel='rbf', C=1)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance using Precision, Recall, and F1-Score\n",
        "precision = metrics.precision_score(y_test, y_pred, average='weighted')\n",
        "recall = metrics.recall_score(y_test, y_pred, average='weighted')\n",
        "f1_score = metrics.f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1_score)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "# Determine which class has the best performance\n",
        "class_performance = metrics.classification_report(y_test, y_pred, output_dict=True)\n",
        "best_class = max(class_performance, key=lambda x: class_performance[x]['f1-score'] if x != 'accuracy' and x != 'macro avg' and x != 'weighted avg' else 0)\n",
        "print(f\"Best performing class: {best_class}\")\n",
        "\n",
        "#42 Write a Python program to train a Na√Øve Bayes Classifier and evaluate its performance using Log Loss (Cross-Entropy Loss)\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Na√Øve Bayes Classifier\n",
        "nb_classifier = GaussianNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_proba = nb_classifier.predict_proba(X_test)\n",
        "\n",
        "# Evaluate the performance using Log Loss\n",
        "log_loss = metrics.log_loss(y_test, y_pred_proba)\n",
        "print(\"Log Loss:\", log_loss)\n",
        "\n",
        "# Predict class labels\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance using accuracy\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "#43 Write a Python program to train an SVM Classifier and visualize the Confusion Matrix using seaborn\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an SVM Classifier\n",
        "svm_classifier = svm.SVC(kernel='rbf', C=1)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Create a Confusion Matrix\n",
        "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize the Confusion Matrix using seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='d')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('Actual Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the performance\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(metrics.classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "\n",
        "#44 Write a Python program to train an SVM Regressor (SVR) and evaluate its performance using Mean Absolute Error (MAE) instead of MSE\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "diabetes = datasets.load_diabetes()\n",
        "X = diabetes.data\n",
        "y = diabetes.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an SVM Regressor\n",
        "svr = svm.SVR(kernel='rbf', C=1)\n",
        "svr.fit(X_train, y_train)\n",
        "y_pred = svr.predict(X_test)\n",
        "\n",
        "# Evaluate the performance using Mean Absolute Error (MAE)\n",
        "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "\n",
        "# Evaluate the performance using Mean Squared Error (MSE) for comparison\n",
        "mse = metrics.mean_squared_error(y_test, y_pred)\n",
        "print(\"Mean Squared Error (MSE):\", mse)\n",
        "\n",
        "# Evaluate the performance using R-Squared\n",
        "r2 = metrics.r2_score(y_test, y_pred)\n",
        "print(\"R-Squared:\", r2)\n",
        "\n",
        "# Plot the actual vs predicted values\n",
        "import matplotlib.pyplot as plt\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel('Actual Values')\n",
        "plt.ylabel('Predicted Values')\n",
        "plt.title('Actual vs Predicted Values')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#45  Write a Python program to train a Na√Øve Bayes classifier and evaluate its performance using the ROC-AUC score\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=0, n_repeated=0, n_classes=2, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Na√Øve Bayes classifier\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_proba = nb.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate the performance using ROC-AUC score\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_proba)\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC Curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "#46 Write a Python program to train an SVM Classifier and visualize the Precision-Recall Curve.\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=0, n_repeated=0, n_classes=2, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train an SVM Classifier\n",
        "svm_classifier = svm.SVC(kernel='rbf', C=1, probability=True)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "y_pred_proba = svm_classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate precision and recall\n",
        "precision, recall, thresholds = metrics.precision_recall_curve(y_test, y_pred_proba)\n",
        "\n",
        "# Calculate the area under the precision-recall curve\n",
        "auc = metrics.auc(recall, precision)\n",
        "print(\"Area under the Precision-Recall Curve:\", auc)\n",
        "\n",
        "# Plot the precision-recall curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, color='darkorange', lw=2, label='Precision-Recall Curve (area = %0.2f)' % auc)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the performance using accuracy\n",
        "y_pred = svm_classifier.predict(X_test)\n",
        "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report:\")\n",
        "print(metrics.classification_report(y_test, y_pred))\n"
      ]
    }
  ]
}